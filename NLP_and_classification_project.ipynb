{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Practical MCQ: NLP and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll explore and evaluate different machine learning classifiers through various tasks like model fitting, parameter tuning, and performance comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Utilise vectorisation techniques to process textual data.\n",
    "- Implement logistic regression and measure its accuracy.\n",
    "- Determine optimal model parameters using grid search.\n",
    "- Interpret the output of machine learning models using confusion matrices.\n",
    "- Analyse the performance of classifiers with precision-recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863c65d",
   "metadata": {},
   "source": [
    "> ⚠️ Please note that the multiple choices to all questions are not included in this notebook; they are available exclusively on the MCQ webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecec55",
   "metadata": {},
   "source": [
    "What does the `CountVectorizer` output `X` represent in the code snippet below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc759b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "data = [\"Machine learning is fascinating.\", \"Natural language processing and machine learning are closely linked.\"]\n",
    "\n",
    "# Initialise the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587274e-4551-42e9-ade5-1d4dc5df22c9",
   "metadata": {},
   "source": [
    "**Answer:** The count of unique words in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccb80d",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Modify the code below to compute and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419ad301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9d0dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc9de7",
   "metadata": {},
   "source": [
    "What is the accuracy of the logistic regression model on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd508e27",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What is the value of True Positive (TP) in the confusion matrix generated by the RandomForestClassifier below? Modify the code to print the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bae0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25577a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  107    8\n",
       "1   22  113"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93542c5b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What is the best value of the parameter 'C' for the SVC according to the grid search? Modify the code to print the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b03d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Load a dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Initialize an SVC (Support Vector Classifier) with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Define parameter range for C (regularization parameter)\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "\n",
    "# Setup the grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a41522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98217731",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Which code snippet can be used to fill in the missing lines of code to train the SVM classifier, predict the test set results, and print the classification report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ac91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       115\n",
      "           1       0.89      0.81      0.85       135\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.85      0.84       250\n",
      "weighted avg       0.85      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier with a radial basis function kernel\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# [Your Code Here] - Line to add for fitting the model\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "# [Your Code Here] - Line to add for making predictions\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# Generate and print the classification report\n",
    "# [Your Code Here] - Line to add for printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e875cb9",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Given the code below, your task is to select the function from the options provided that correctly completes the task by:\n",
    "\n",
    "i) Creating a function that determines which classifier (KNN or Naive Bayes) has a higher F1 score, or if they have equal scores.\n",
    "\n",
    "ii) Printing the name of the classifier along with its F1 score in the format: 'ClassifierName has the higher F1 score of Score' or 'Both classifiers have the same F1 score of Score'.\n",
    "\n",
    "iii) Executing the function.\n",
    "\n",
    "Select the appropriate code snippet from the options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6953839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has the higher F1 score of 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize KNN and Naive Bayes classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train both classifiers on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results for both classifiers\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate F1 scores for both classifiers\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "# [Your Code Here]\n",
    "def print_best_classifier(f1_knn, f1_nb):\n",
    "    if f1_knn > f1_nb:\n",
    "        print(f\"KNN has the higher F1 score of {f1_knn}\")\n",
    "    elif f1_knn < f1_nb:\n",
    "        print(f\"Naive Bayes has the higher F1 score of {f1_nb}\")\n",
    "    else:\n",
    "        print(f\"Both classifiers have the same F1 score of {f1_knn}\")\n",
    "print_best_classifier(f1_knn, f1_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9667f9",
   "metadata": {},
   "source": [
    "## Question  7 \n",
    "\n",
    "Which of the following options will complete the missing code lines to:\n",
    "\n",
    "i) train the MLPClassifier, \n",
    "\n",
    "ii) predict the test set labels,\n",
    "\n",
    "iii) count the number of misclassified samples,\n",
    "\n",
    "iv) call the function to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b4c48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate a two-moon dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialise the MLPClassifier with one hidden layer with 10 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# [Your Code Here] - Train the MLPClassifier on the scaled training data\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# [Your Code Here] - Predict the labels for the scaled test data\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# [Your Code Here] - Print the number of misclassified samples in the test set\n",
    "print (np.sum(y_test != y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8065ab7",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Before running the final line of the code in the snippet below to fit the `grid_search` object, you are asked to perform the following tasks directly in the code:\n",
    "\n",
    "1. Modify the `param_grid` to include a new parameter: `'max_features'` with values ranging from 1 to 4.\n",
    "2. Fit the `grid_search` to the training data.\n",
    "3. After fitting, extract and print the best parameter combination and the corresponding cross-validation score.\n",
    "\n",
    "Which of the following options correctly completes these tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eba25b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Best Params: {'max_depth': None, 'max_features': 2, 'min_samples_split': 20}, CV Score: 0.9371541501976285\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setup a basic decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid over which to optimize the decision tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
    "\n",
    "param_grid['max_features'] = range(1, 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Params: {grid_search.best_params_}, CV Score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b112d7e",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "You are fine-tuning a decision tree classifier for a marketing dataset. To prevent overfitting and ensure robust generalisability, you must adjust the depth of the decision tree after its initialisation but before it is fitted with data. Considering the decision tree `dt` has already been initialised with a random state, which of the following is the correct way to modify the tree's maximum depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38372bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# [Your Code Here\n",
    "dt.set_params(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537192ee",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Suppose you are analysing the performance of a new email spam detection system using precision and recall. You have already computed these metrics, and you are about to explore their trade-offs to optimise the classifier's threshold. Given the code snippet below, identify the correct function call that would allow you to adjust and visualise the precision-recall trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b858357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_scores = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# [Your Code Here] - Generate precision and recall values for various thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198463ec",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "You are tasked with enhancing the robustness of a logistic regression model by incorporating feature scaling. You're currently working with a dataset that has significantly varying scales among its features, which can affect the model's performance. Below is a preliminary setup for the logistic regression model. Identify the correct sequence of steps to integrate feature scaling into the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# [Your Code Here] - Apply feature scaling to the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# [Your Code Here] - Fit the model on the scaled training data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# [Your Code Here] - Apply the same scaling to the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9ab5e",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "\n",
    "You are fine-tuning a support vector machine (SVM) classifier to categorise images based on their content. The dataset consists of various animal images, and you suspect that different kernel functions might yield better classification accuracy. You decide to test which SVM kernel—linear or radial basis function (RBF)—works best for your specific dataset. Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a dataset of digit images\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize two SVM classifiers, one with a linear kernel and another with an RBF kernel\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# [Your Code Here] - Train both classifiers on the training data\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# [Your Code Here] - Predict the test set results with both classifiers\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# [Your Code Here] - Calculate and print the accuracy scores for both classifiers\n",
    "print(\"Linear Accuracy:\", accuracy_score(y_test, y_pred_linear))\n",
    "print(\"RBF Accuracy:\", accuracy_score(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097f7ae",
   "metadata": {},
   "source": [
    "Which of the following options correctly completes the task of training both SVM classifiers, predicting the test set results, and calculating the accuracy for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3dfa",
   "metadata": {},
   "source": [
    "## Question 13 \n",
    "\n",
    "You are currently evaluating two classifiers, K-Nearest Neighbours (KNN) and Naive Bayes, for a project that involves classifying texts into different categories based on their content. To finalise your model selection, you decide to visually compare their performance using a bar chart. Below is the setup for calculating the accuracy of both models on your dataset. Complete the code by adding the necessary lines to plot the accuracies in a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = fetch_20newsgroups(subset='all')\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialise classifiers\n",
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train classifiers\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn.predict(X_test_tfidf))\n",
    "nb_accuracy = accuracy_score(y_test, nb.predict(X_test_tfidf))\n",
    "\n",
    "# [Your code here] - Plot the accuracies in a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7fc31f6-ceb5-4d6a-a510-78154f493bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFWUlEQVR4nO3deVhV1f7H8Q9ggIjggIIiV3JIJRUMk4taapE4lpZlZqI43LIoi+oqaZiaYlmGmmU5l2MOebtpmpH2q6QwTdMyzRErQVEDxYSE9fujx3M7MQiIHty9X8+zn6ez9tprf/eBEx/XHo6TMcYIAADAIpwdXQAAAEB5ItwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdwAAABLIdzgbyswMFCDBg1y2P4HDRqkwMBAu7azZ89q6NCh8vPzk5OTk5544gkdPnxYTk5OWrBggUPqBMqisN9v4Goh3MByDhw4oIceekgNGjSQu7u7vLy81K5dO02bNk2//fabo8sr1qRJk7RgwQINHz5c77zzjgYMGOCwWvbs2SMnJye5u7vr119/dVgd16rz58/r1VdfVVhYmLy9veXu7q4bbrhBMTEx2rdvn6PLAyzNie+WgpWsXbtW9957r9zc3BQVFaXmzZsrNzdXn3/+uVatWqVBgwbprbfekvTHzE3Hjh0dNiPy+++/Kz8/X25ubra2f/7zn6pUqZI+//xzW5sxRjk5Obruuuvk4uJy1eobPXq05s2bp9OnT+u1117T0KFDr9q+r3UZGRnq0qWLtm3bph49eigiIkKenp7au3evli1bprS0NOXm5jq6zCuqsN9v4Gqp5OgCgPJy6NAh3X///apfv74++eQT1alTx7bu0Ucf1f79+7V27VoHVmjvuuuuK9B2/PhxBQUF2bVdnD0pL9nZ2apSpUqxfYwxWrJkiR544AEdOnRIixcvrrDhpiTHc7UNGjRI33zzjVauXKl77rnHbt2ECRM0evRoB1V25V38eRT2+w1cNQawiIcffthIMl988UWJ+tevX98MHDjQ9vrkyZPmqaeeMs2bNzdVqlQxVatWNV26dDE7duwosO306dNNUFCQqVy5sqlWrZoJDQ01ixcvtq3PysoyI0aMMPXr1zeurq6mVq1aJiIiwmzbts3WZ+DAgaZ+/frGGGM2bdpkJBVYDh06ZA4dOmQkmfnz59vVsGfPHnPPPfeY6tWrGzc3NxMaGmr+85//2PWZP3++kWQ2b95shg8fbmrVqmWqVat2yffms88+M5JMSkqKWb58uXF2djZHjx4t0C8vL88kJiaa5s2bGzc3N+Pj42MiIyPN1q1b7fq988475uabb7a9X7fccovZsGGDbb0kM3bs2ALj//VnVNzxHD582AwfPtzccMMNxt3d3dSoUcP06dPHHDp0qMC4p0+fNk888YTt5+Pv728GDBhgTpw4Yc6cOWM8PDzM448/XmC7o0ePGmdnZzNp0qQi37svv/zSSDLDhg0rss9fJSUlmfbt2xsPDw/j7e1t7rzzTvP999/b9Rk7dqyRZPbu3Wv69+9vvLy8jI+PjxkzZozJz883qamp5s477zRVq1Y1vr6+5uWXX7bb/uLv2LJly0xcXJzx9fU1Hh4epmfPniY1NdWu7//93/+ZPn36mICAAOPq6mrq1atnnnjiCXPu3Dm7fgMHDjRVqlQx+/fvN127djWenp7mrrvusq27+Pt90dKlS81NN91kPD09TdWqVU3z5s1NYmKiXZ8DBw6YPn36mOrVq5vKlSubsLAw88EHHxR6LMuXLzcvvPCC8ff3N25ubua2224zP/74Y4nfd1gXMzewjP/+979q0KCB2rZtW6btDx48qDVr1ujee+/V9ddfr/T0dL355pvq0KGDvv/+e9WtW1eSNHv2bD3++OPq06ePRowYofPnz+vbb7/VV199pQceeECS9PDDD2vlypWKiYlRUFCQTp48qc8//1x79uzRTTfdVGDfzZo10zvvvKMnn3xS9erV01NPPSVJqlWrlk6cOFGg/3fffad27drJ399fo0aNUpUqVfTuu++qV69eWrVqlXr37m3X/5FHHlGtWrUUHx+v7OzsS74XixcvVsOGDXXzzTerefPm8vDw0NKlS/XMM8/Y9RsyZIgWLFigrl27aujQobpw4YI+++wzffnll2rdurUkady4cXr++efVtm1bjR8/Xq6urvrqq6/0ySefqHPnziX4yRRU2PFs3bpVW7Zs0f3336969erp8OHDeuONN9SxY0d9//338vDwkPTHRdu33HKL9uzZo8GDB+umm25SRkaG3n//ff30008KCQlR7969tXz5ck2dOtXuVODSpUtljFH//v2LrO3999+XpBJfL/Xxxx+ra9euatCggZ5//nn99ttvmjFjhtq1a6ft27cXuCi3b9++atasmSZPnqy1a9fqhRdeUI0aNfTmm2/qtttu04svvqjFixfr6aef1s0336xbb73VbvuJEyfKyclJI0eO1PHjx5WYmKiIiAjt2LFDlStXliStWLFC586d0/Dhw1WzZk2lpKRoxowZ+umnn7RixQq78S5cuKDIyEi1b99eL7/8su19/quNGzeqX79+uv322/Xiiy9K+uO6ri+++EIjRoyQJKWnp6tt27Y6d+6cHn/8cdWsWVMLFy7UnXfeqZUrVxb4vZ48ebKcnZ319NNPKzMzUy+99JL69++vr776qkTvPSzM0ekKKA+ZmZlGku1fjSXx11mB8+fPm7y8PLs+hw4dMm5ubmb8+PG2trvuusvceOONxY7t7e1tHn300WL7FPYv2/r165vu3bsXqEF/mbm5/fbbTYsWLcz58+dtbfn5+aZt27amcePGtraLMx3t27c3Fy5cKLaei3Jzc03NmjXN6NGjbW0PPPCACQ4Otuv3ySefGEmFznDk5+cbY4z58ccfjbOzs+ndu3eB9/ZiH2NKP3NT2PH8dVbBGGOSk5ONJPP222/b2uLj440ks3r16iLr3rBhg5FkPvzwQ7v1LVu2NB06dCiw3Z/17t3bSDKnT58utt9FISEhpnbt2ubkyZO2tp07dxpnZ2cTFRVla7s4c/Ovf/3L1nbhwgVTr1494+TkZCZPnmxrP336tKlcubLde3dxtsPf399kZWXZ2t99910jyUybNs3WVth7mZCQYJycnMyRI0dsbQMHDjSSzKhRowr0/+vv94gRI4yXl1exv4dPPPGEkWQ+++wzW9uZM2fM9ddfbwIDA22/QxePpVmzZiYnJ8fWd9q0aUaS2bVrV5H7wN8Dd0vBErKysiRJVatWLfMYbm5ucnb+4yORl5enkydPytPTU02aNNH27dtt/apVq6affvpJW7duLXKsatWq6auvvtIvv/xS5nqKcurUKX3yySe67777dObMGWVkZCgjI0MnT55UZGSkfvzxR/3888922wwbNqzEFyN/+OGHOnnypPr162dr69evn3bu3KnvvvvO1rZq1So5OTlp7NixBcZwcnKSJK1Zs0b5+fmKj4+3vbd/7VMWhR3PxVkH6Y+LWU+ePKlGjRqpWrVqdj+/VatWKTg4uMAswJ9rioiIUN26dbV48WLbut27d+vbb7/Vgw8+WGxtpfldPHbsmHbs2KFBgwapRo0atvaWLVvqjjvu0Lp16wps8+drn1xcXNS6dWsZYzRkyBBbe7Vq1dSkSRMdPHiwwPZRUVF2tfXp00d16tSx29ef38vs7GxlZGSobdu2Msbom2++KTDm8OHDL3ms1apVU3Z2tjZu3Fhkn3Xr1qlNmzZq3769rc3T01P/+te/dPjwYX3//fd2/aOjo+Xq6mp7fcstt0hSoceNvxfCDSzBy8tLknTmzJkyj5Gfn69XX31VjRs3lpubm3x8fFSrVi19++23yszMtPUbOXKkPD091aZNGzVu3FiPPvqovvjiC7uxXnrpJe3evVsBAQFq06aNnn/++XL7H+7+/ftljNFzzz2nWrVq2S0Xg8bx48fttrn++utLPP6iRYt0/fXXy83NTfv379f+/fvVsGFDeXh42P2xP3DggOrWrWv3R/mvDhw4IGdn5wIXSV+uwo7nt99+U3x8vAICAux+fr/++qvdz+/AgQNq3rx5seM7Ozurf//+WrNmjc6dOyfpj1N17u7uuvfee4vdtjS/i0eOHJEkNWnSpMC6Zs2aKSMjo8BpxH/84x92ry/eZu7j41Og/fTp0wXGbdy4sd1rJycnNWrUSIcPH7a1paam2gKXp6enatWqpQ4dOkiS3XspSZUqVVK9evUucaR/nEq84YYb1LVrV9WrV0+DBw/W+vXr7focOXKkyPfi4vo/++t7Ub16dUkq9Ljx90K4gSV4eXmpbt262r17d5nHmDRpkmJjY3Xrrbdq0aJF2rBhgzZu3Kgbb7xR+fn5tn7NmjWz3dLbvn17rVq1Su3bt7ebwbjvvvt08OBBzZgxQ3Xr1tWUKVN044036sMPP7ys45Rkq+Xpp5/Wxo0bC10aNWpkt82f/yVenKysLP33v//VoUOH1LhxY9sSFBSkc+fOacmSJTJX8ekReXl5hbYXdjyPPfaYJk6cqPvuu0/vvvuuPvroI23cuFE1a9a0+/mVVFRUlM6ePas1a9bY7h7r0aOHvL29i92uadOmkqRdu3aVep8lUdgMXFGzcmX5WeXl5emOO+7Q2rVrNXLkSK1Zs0YbN260PTLhr+/ln2c8i1O7dm3t2LFD77//vu68805t2rRJXbt21cCBA0td40XledywFi4ohmX06NFDb731lpKTkxUeHl7q7VeuXKlOnTpp7ty5du2//vprgX8VV6lSRX379lXfvn2Vm5uru+++WxMnTlRcXJzttu06derokUce0SOPPKLjx4/rpptu0sSJE9W1a9eyH6SkBg0aSPrjVvKIiIjLGuuvVq9erfPnz+uNN94ocMx79+7VmDFj9MUXX6h9+/Zq2LChNmzYoFOnThU5e9OwYUPl5+fr+++/V0hISJH7rV69eoEHBebm5urYsWMlrn3lypUaOHCgXnnlFVvb+fPnC4zbsGHDEoXg5s2bq1WrVlq8eLHq1aun1NRUzZgx45Lb9ezZUwkJCVq0aJHtNElR6tevL+mP9/avfvjhB/n4+JT7be4//vij3WtjjPbv36+WLVtK+iOU7du3TwsXLlRUVJStX3Gnk0rK1dVVPXv2VM+ePZWfn69HHnlEb775pp577jk1atRI9evXL/K9kP73fgGXwswNLOPf//63qlSpoqFDhyo9Pb3A+gMHDmjatGlFbu/i4lLgX3wrVqwocP3KyZMn7V67uroqKChIxhj9/vvvysvLKzB1X7t2bdWtW1c5OTmlPawCateurY4dO+rNN98s9I9/YXdXldSiRYvUoEEDPfzww+rTp4/d8vTTT8vT09N2auqee+6RMUbjxo0rMM7F97FXr15ydnbW+PHjC/yL/8/vdcOGDfV///d/duvfeuutImduClPYz2/GjBkFxrjnnnu0c+dOvffee0XWfdGAAQP00UcfKTExUTVr1ixRMA0PD1eXLl00Z84crVmzpsD63NxcPf3005L+CMAhISFauHChXQjbvXu3PvroI3Xr1u2S+yutt99+2+6U2cqVK3Xs2DHbsV2cDfnze2GMKfazUxJ//dw4OzvbAtXFz0W3bt2UkpKi5ORkW7/s7Gy99dZbCgwMLPfTm7AuZm5gGQ0bNtSSJUtst8r++QnFW7Zs0YoVK4r9LqkePXpo/Pjxio6OVtu2bbVr1y4tXrzYNlNyUefOneXn56d27drJ19dXe/bs0Wuvvabu3buratWq+vXXX1WvXj316dNHwcHB8vT01Mcff6ytW7fazSpcjpkzZ6p9+/Zq0aKFhg0bpgYNGig9PV3Jycn66aeftHPnzlKP+csvv2jTpk16/PHHC13v5uamyMhIrVixQtOnT1enTp00YMAATZ8+XT/++KO6dOmi/Px8ffbZZ+rUqZNiYmLUqFEjjR49WhMmTNAtt9yiu+++W25ubtq6davq1q2rhIQESX9cJPvwww/rnnvu0R133KGdO3dqw4YNBWaPitOjRw+988478vb2VlBQkJKTk/Xxxx+rZs2adv2eeeYZrVy5Uvfee68GDx6s0NBQnTp1Su+//75mzZql4OBgW98HHnhA//73v/Xee+9p+PDhJX4w3dtvv63OnTvr7rvvVs+ePXX77berSpUq+vHHH7Vs2TIdO3ZML7/8siRpypQp6tq1q8LDwzVkyBDbreDe3t56/vnnS3z8JVWjRg21b99e0dHRSk9PV2Jioho1aqRhw4ZJ+uO0WsOGDfX000/r559/lpeXl1atWnXZ17EMHTpUp06d0m233aZ69erpyJEjmjFjhkJCQmzX1IwaNUpLly5V165d9fjjj6tGjRpauHChDh06pFWrVpXo9BcgiVvBYT379u0zw4YNM4GBgcbV1dVUrVrVtGvXzsyYMcPu1unCbgV/6qmnTJ06dUzlypVNu3btTHJysunQoYPd7b9vvvmmufXWW03NmjWNm5ubadiwoXnmmWdMZmamMcaYnJwc88wzz5jg4GBTtWpVU6VKFRMcHGxef/11uzov51ZwY/542FlUVJTx8/Mz1113nfH39zc9evQwK1eutPW5eOv0Xx+qV5hXXnnFSDJJSUlF9lmwYIGRZHtY4IULF8yUKVNM06ZNbQ8r7Nq1q93DCo0xZt68eaZVq1bGzc3NVK9e3XTo0MFs3LjRtj4vL8+MHDnS+Pj4GA8PDxMZGWn2799f5K3ghR3P6dOnTXR0tPHx8TGenp4mMjLS/PDDDwXGMOaPBzbGxMQYf39/20PqBg4caDIyMgqM261bNyPJbNmy5ZLv4Z+dO3fOvPzyy+bmm282np6extXV1TRu3Ng89thjZv/+/XZ9P/74Y9OuXTtTuXJl4+XlZXr27FnkQ/xOnDhh137xQXp/1aFDB7tHFly8fXrp0qUmLi7O1K5d21SuXNl0797d7vZuY4z5/vvvTUREhPH09DQ+Pj5m2LBhZufOnQV+D4va98V1f/79XrlypencubOpXbu2cXV1Nf/4xz/MQw89ZI4dO2a33cWH+FWrVs24u7ubNm3aFPkQvxUrVti1F/VZwd8P3y0FAMXo3bu3du3apf379zu6lMuyefNmderUSStWrFCfPn0cXQ5wRTHHBwBFOHbsmNauXevQb2cHUHpccwMAf3Ho0CF98cUXmjNnjq677jo99NBDji4JQCkwcwMAf/Hpp59qwIABOnTokBYuXCg/Pz9HlwSgFLjmBgAAWAozNwAAwFIINwAAwFL+dhcU5+fn65dfflHVqlUv61uJAQDA1WOM0ZkzZ1S3bt1LPtDxbxdufvnlFwUEBDi6DAAAUAZHjx695DfR/+3CTdWqVSX98eZ4eXk5uBoAAFASWVlZCggIsP0dL87fLtxcPBXl5eVFuAEA4BpTkktKuKAYAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYSiVHFwAA15rAUWsdXQJQoR2e3N2h+2fmBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWIrDw83MmTMVGBgod3d3hYWFKSUlpdj+iYmJatKkiSpXrqyAgAA9+eSTOn/+/FWqFgAAVHQODTfLly9XbGysxo4dq+3btys4OFiRkZE6fvx4of2XLFmiUaNGaezYsdqzZ4/mzp2r5cuX69lnn73KlQMAgIrKoeFm6tSpGjZsmKKjoxUUFKRZs2bJw8ND8+bNK7T/li1b1K5dOz3wwAMKDAxU586d1a9fv0vO9gAAgL+PSo7acW5urrZt26a4uDhbm7OzsyIiIpScnFzoNm3bttWiRYuUkpKiNm3a6ODBg1q3bp0GDBhQ5H5ycnKUk5Nje52VlVV+B1GIwFFrr+j4wLXs8OTuji4BwN+Aw8JNRkaG8vLy5Ovra9fu6+urH374odBtHnjgAWVkZKh9+/YyxujChQt6+OGHiz0tlZCQoHHjxpVr7QAAoOJy+AXFpbF582ZNmjRJr7/+urZv367Vq1dr7dq1mjBhQpHbxMXFKTMz07YcPXr0KlYMAACuNofN3Pj4+MjFxUXp6el27enp6fLz8yt0m+eee04DBgzQ0KFDJUktWrRQdna2/vWvf2n06NFydi6Y1dzc3OTm5lb+BwAAACokh83cuLq6KjQ0VElJSba2/Px8JSUlKTw8vNBtzp07VyDAuLi4SJKMMVeuWAAAcM1w2MyNJMXGxmrgwIFq3bq12rRpo8TERGVnZys6OlqSFBUVJX9/fyUkJEiSevbsqalTp6pVq1YKCwvT/v379dxzz6lnz562kAMAAP7eHBpu+vbtqxMnTig+Pl5paWkKCQnR+vXrbRcZp6am2s3UjBkzRk5OThozZox+/vln1apVSz179tTEiRMddQgAAKCCcTJ/s/M5WVlZ8vb2VmZmpry8vMp9fG4FB4pmlVvB+ZwDxbsSn/XS/P2+pu6WAgAAuBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsJQKEW5mzpypwMBAubu7KywsTCkpKUX27dixo5ycnAos3bt3v4oVAwCAisrh4Wb58uWKjY3V2LFjtX37dgUHBysyMlLHjx8vtP/q1at17Ngx27J79265uLjo3nvvvcqVAwCAisjh4Wbq1KkaNmyYoqOjFRQUpFmzZsnDw0Pz5s0rtH+NGjXk5+dnWzZu3CgPDw/CDQAAkOTgcJObm6tt27YpIiLC1ubs7KyIiAglJyeXaIy5c+fq/vvvV5UqVQpdn5OTo6ysLLsFAABYl0PDTUZGhvLy8uTr62vX7uvrq7S0tEtun5KSot27d2vo0KFF9klISJC3t7dtCQgIuOy6AQBAxeXw01KXY+7cuWrRooXatGlTZJ+4uDhlZmbalqNHj17FCgEAwNVWyZE79/HxkYuLi9LT0+3a09PT5efnV+y22dnZWrZsmcaPH19sPzc3N7m5uV12rQAA4Nrg0JkbV1dXhYaGKikpydaWn5+vpKQkhYeHF7vtihUrlJOTowcffPBKlwkAAK4hDp25kaTY2FgNHDhQrVu3Vps2bZSYmKjs7GxFR0dLkqKiouTv76+EhAS77ebOnatevXqpZs2ajigbAABUUA4PN3379tWJEycUHx+vtLQ0hYSEaP369baLjFNTU+XsbD/BtHfvXn3++ef66KOPHFEyAACowBwebiQpJiZGMTExha7bvHlzgbYmTZrIGHOFqwIAANeia/puKQAAgL8i3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEtxeLiZOXOmAgMD5e7urrCwMKWkpBTb/9dff9Wjjz6qOnXqyM3NTTfccIPWrVt3laoFAAAVXSVH7nz58uWKjY3VrFmzFBYWpsTEREVGRmrv3r2qXbt2gf65ubm64447VLt2ba1cuVL+/v46cuSIqlWrdvWLBwAAFZJDw83UqVM1bNgwRUdHS5JmzZqltWvXat68eRo1alSB/vPmzdOpU6e0ZcsWXXfddZKkwMDAq1kyAACo4Bx2Wio3N1fbtm1TRETE/4pxdlZERISSk5ML3eb9999XeHi4Hn30Ufn6+qp58+aaNGmS8vLyrlbZAACggnPYzE1GRoby8vLk6+tr1+7r66sffvih0G0OHjyoTz75RP3799e6deu0f/9+PfLII/r99981duzYQrfJyclRTk6O7XVWVlb5HQQAAKhwHH5BcWnk5+erdu3aeuuttxQaGqq+fftq9OjRmjVrVpHbJCQkyNvb27YEBARcxYoBAMDV5rBw4+PjIxcXF6Wnp9u1p6eny8/Pr9Bt6tSpoxtuuEEuLi62tmbNmiktLU25ubmFbhMXF6fMzEzbcvTo0fI7CAAAUOE4LNy4uroqNDRUSUlJtrb8/HwlJSUpPDy80G3atWun/fv3Kz8/39a2b98+1alTR66uroVu4+bmJi8vL7sFAABYl0NPS8XGxmr27NlauHCh9uzZo+HDhys7O9t291RUVJTi4uJs/YcPH65Tp05pxIgR2rdvn9auXatJkybp0UcfddQhAACACsaht4L37dtXJ06cUHx8vNLS0hQSEqL169fbLjJOTU2Vs/P/8ldAQIA2bNigJ598Ui1btpS/v79GjBihkSNHOuoQAABABePQcCNJMTExiomJKXTd5s2bC7SFh4fryy+/vMJVAQCAa9U1dbcUAADApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApZQ63Fy4cEHjx4/XTz/9dCXqAQAAuCylDjeVKlXSlClTdOHChStRDwAAwGUp02mp2267TZ9++ml51wIAAHDZKpVlo65du2rUqFHatWuXQkNDVaVKFbv1d955Z6nGmzlzpqZMmaK0tDQFBwdrxowZatOmTaF9FyxYoOjoaLs2Nzc3nT9/vnQHAQAALKlM4eaRRx6RJE2dOrXAOicnJ+Xl5ZV4rOXLlys2NlazZs1SWFiYEhMTFRkZqb1796p27dqFbuPl5aW9e/fa7RMAAEAq42mp/Pz8IpfSBBvpj4A0bNgwRUdHKygoSLNmzZKHh4fmzZtX5DZOTk7y8/OzLb6+vmU5DAAAYEGXfSv45ZwOys3N1bZt2xQREfG/gpydFRERoeTk5CK3O3v2rOrXr6+AgADddddd+u6774rsm5OTo6ysLLsFAABYV5nCTV5eniZMmCB/f395enrq4MGDkqTnnntOc+fOLfE4GRkZysvLKzDz4uvrq7S0tEK3adKkiebNm6f//Oc/WrRokfLz89W2bdsib01PSEiQt7e3bQkICChxfQAA4NpTpnAzceJELViwQC+99JJcXV1t7c2bN9ecOXPKrbjChIeHKyoqSiEhIerQoYNWr16tWrVq6c033yy0f1xcnDIzM23L0aNHr2h9AADAscoUbt5++2299dZb6t+/v1xcXGztwcHB+uGHH0o8jo+Pj1xcXJSenm7Xnp6eLj8/vxKNcd1116lVq1bav39/oevd3Nzk5eVltwAAAOsqU7j5+eef1ahRowLt+fn5+v3330s8jqurq0JDQ5WUlGQ3RlJSksLDw0s0Rl5ennbt2qU6deqUeL8AAMC6yhRugoKC9NlnnxVoX7lypVq1alWqsWJjYzV79mwtXLhQe/bs0fDhw5WdnW17lk1UVJTi4uJs/cePH6+PPvpIBw8e1Pbt2/Xggw/qyJEjGjp0aFkOBQAAWEyZnnMTHx+vgQMH6ueff1Z+fr5Wr16tvXv36u2339YHH3xQqrH69u2rEydOKD4+XmlpaQoJCdH69ettFxmnpqbK2fl/Gez06dMaNmyY0tLSVL16dYWGhmrLli0KCgoqy6EAAACLcTLGmLJs+Nlnn2n8+PHauXOnzp49q5tuuknx8fHq3LlzeddYrrKysuTt7a3MzMwrcv1N4Ki15T4mYBWHJ3d3dAnlgs85ULwr8Vkvzd/vMs3cSNItt9yijRs3lnVzAACAK+KyH+IHAABQkZR45qZGjRrat2+ffHx8VL169WK/z+nUqVPlUhwAAEBplTjcvPrqq6pataokKTEx8UrVAwAAcFlKHG527typPn36yM3NTddff73atm2rSpXKfMkOAADAFVHia25mzJihs2fPSpI6derEqScAAFAhlXjqJTAwUNOnT1fnzp1ljFFycrKqV69eaN9bb7213AoEAAAojRKHmylTpujhhx9WQkKCnJyc1Lt370L7OTk5KS8vr9wKBAAAKI0Sh5tevXqpV69eOnv2rLy8vLR3717Vrl37StYGAABQaqW+ItjT01ObNm3S9ddfzwXFAACgwilxOsnKyrI97rhVq1Y6d+5ckX2vxNcaAAAAlESJw0316tV17Ngx1a5dW9WqVSv0IX7GGK65AQAADlXicPPJJ5+oRo0akqRNmzZdsYIAAAAuR4nDTYcOHQr9bwAAgIqkTF+cuX79en3++ee21zNnzlRISIgeeOABnT59utyKAwAAKK0yhZtnnnlGWVlZkqRdu3YpNjZW3bp106FDhxQbG1uuBQIAAJRGme7lPnTokIKCgiRJq1atUs+ePTVp0iRt375d3bp1K9cCAQAASqNMMzeurq62W8E//vhjde7cWZJUo0YN24wOAACAI5Rp5qZ9+/aKjY1Vu3btlJKSouXLl0uS9u3bp3r16pVrgQAAAKVRppmb1157TZUqVdLKlSv1xhtvyN/fX5L04YcfqkuXLuVaIAAAQGmUaebmH//4hz744IMC7a+++uplFwQAAHA5yjRzs337du3atcv2+j//+Y969eqlZ599Vrm5ueVWHAAAQGmVKdw89NBD2rdvnyTp4MGDuv/+++Xh4aEVK1bo3//+d7kWCAAAUBplCjf79u1TSEiIJGnFihW69dZbtWTJEi1YsECrVq0qz/oAAABKpUzhxhij/Px8SX/cCn7x2TYBAQHKyMgov+oAAABKqUzhpnXr1nrhhRf0zjvv6NNPP1X37t0l/fFwP19f33ItEAAAoDTKFG4SExO1fft2xcTEaPTo0WrUqJEkaeXKlWrbtm25FggAAFAaZboVvGXLlnZ3S100ZcoUubi4XHZRAAAAZVWmcFMUd3f38hwOAACg1MoUbvLy8vTqq6/q3XffVWpqaoFn25w6dapcigMAACitMl1zM27cOE2dOlV9+/ZVZmamYmNjdffdd8vZ2VnPP/98qcebOXOmAgMD5e7urrCwMKWkpJRou2XLlsnJyUm9evUq9T4BAIA1lSncLF68WLNnz9ZTTz2lSpUqqV+/fpozZ47i4+P15Zdflmqs5cuXKzY2VmPHjtX27dsVHBysyMhIHT9+vNjtDh8+rKefflq33HJLWQ4BAABYVJnCTVpamlq0aCFJ8vT0VGZmpiSpR48eWrt2banGmjp1qoYNG6bo6GgFBQVp1qxZ8vDw0Lx584rcJi8vT/3799e4cePUoEGDshwCAACwqDKFm3r16unYsWOSpIYNG+qjjz6SJG3dulVubm4lHic3N1fbtm1TRETE/wpydlZERISSk5OL3G78+PGqXbu2hgwZUpbyAQCAhZXpguLevXsrKSlJYWFheuyxx/Tggw9q7ty5Sk1N1ZNPPlnicTIyMpSXl1fgwX++vr764YcfCt3m888/19y5c7Vjx44S7SMnJ0c5OTm211lZWSWuDwAAXHvKFG4mT55s++++ffvqH//4h5KTk9W4cWP17Nmz3Ir7qzNnzmjAgAGaPXu2fHx8SrRNQkKCxo0bd8VqAgAAFUu5POcmPDxc4eHhpd7Ox8dHLi4uSk9Pt2tPT0+Xn59fgf4HDhzQ4cOH7QLUxe+4qlSpkvbu3auGDRvabRMXF6fY2Fjb66ysLAUEBJS6VgAAcG0ocbh5//33SzzonXfeWaJ+rq6uCg0NVVJSku127vz8fCUlJSkmJqZA/6ZNmxZ4MvKYMWN05swZTZs2rdDQ4ubmVqrrgAAAwLWtxOGmpM+ScXJyUl5eXokLiI2N1cCBA9W6dWu1adNGiYmJys7OVnR0tCQpKipK/v7+SkhIkLu7u5o3b263fbVq1SSpQDsAAPh7KnG4uXj6p7z17dtXJ06cUHx8vNLS0hQSEqL169fbLjJOTU2Vs3OZbuoCAAB/Q6VKDZ988omCgoIKveMoMzNTN954oz777LNSFxETE6MjR44oJydHX331lcLCwmzrNm/erAULFhS57YIFC7RmzZpS7xMAAFhTqcJNYmKihg0bJi8vrwLrvL299dBDD2nq1KnlVhwAAEBplSrc7Ny5U126dClyfefOnbVt27bLLgoAAKCsShVu0tPTdd111xW5vlKlSjpx4sRlFwUAAFBWpQo3/v7+2r17d5Hrv/32W9WpU+eyiwIAACirUoWbbt266bnnntP58+cLrPvtt980duxY9ejRo9yKAwAAKK1SPaF4zJgxWr16tW644QbFxMSoSZMmkqQffvhBM2fOVF5enkaPHn1FCgUAACiJUoUbX19fbdmyRcOHD1dcXJyMMZL+eHBfZGSkZs6cWeBLMAEAAK6mUn+3VP369bVu3TqdPn1a+/fvlzFGjRs3VvXq1a9EfQAAAKVS5i/OrF69um6++ebyrAUAAOCy8b0GAADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUgg3AADAUipEuJk5c6YCAwPl7u6usLAwpaSkFNl39erVat26tapVq6YqVaooJCRE77zzzlWsFgAAVGQODzfLly9XbGysxo4dq+3btys4OFiRkZE6fvx4of1r1Kih0aNHKzk5Wd9++62io6MVHR2tDRs2XOXKAQBAReTwcDN16lQNGzZM0dHRCgoK0qxZs+Th4aF58+YV2r9jx47q3bu3mjVrpoYNG2rEiBFq2bKlPv/886tcOQAAqIgcGm5yc3O1bds2RURE2NqcnZ0VERGh5OTkS25vjFFSUpL27t2rW2+9tdA+OTk5ysrKslsAAIB1OTTcZGRkKC8vT76+vnbtvr6+SktLK3K7zMxMeXp6ytXVVd27d9eMGTN0xx13FNo3ISFB3t7etiUgIKBcjwEAAFQsDj8tVRZVq1bVjh07tHXrVk2cOFGxsbHavHlzoX3j4uKUmZlpW44ePXp1iwUAAFdVJUfu3MfHRy4uLkpPT7drT09Pl5+fX5HbOTs7q1GjRpKkkJAQ7dmzRwkJCerYsWOBvm5ubnJzcyvXugEAQMXl0JkbV1dXhYaGKikpydaWn5+vpKQkhYeHl3ic/Px85eTkXIkSAQDANcahMzeSFBsbq4EDB6p169Zq06aNEhMTlZ2drejoaElSVFSU/P39lZCQIOmPa2hat26thg0bKicnR+vWrdM777yjN954w5GHAQAAKgiHh5u+ffvqxIkTio+PV1pamkJCQrR+/XrbRcapqalydv7fBFN2drYeeeQR/fTTT6pcubKaNm2qRYsWqW/fvo46BAAAUIE4GWOMo4u4mrKysuTt7a3MzEx5eXmV+/iBo9aW+5iAVRye3N3RJZQLPudA8a7EZ700f7+vybulAAAAikK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAllIhws3MmTMVGBgod3d3hYWFKSUlpci+s2fP1i233KLq1aurevXqioiIKLY/AAD4e3F4uFm+fLliY2M1duxYbd++XcHBwYqMjNTx48cL7b9582b169dPmzZtUnJysgICAtS5c2f9/PPPV7lyAABQETk83EydOlXDhg1TdHS0goKCNGvWLHl4eGjevHmF9l+8eLEeeeQRhYSEqGnTppozZ47y8/OVlJR0lSsHAAAVkUPDTW5urrZt26aIiAhbm7OzsyIiIpScnFyiMc6dO6fff/9dNWrUuFJlAgCAa0glR+48IyNDeXl58vX1tWv39fXVDz/8UKIxRo4cqbp169oFpD/LyclRTk6O7XVWVlbZCwYAABWew09LXY7Jkydr2bJleu+99+Tu7l5on4SEBHl7e9uWgICAq1wlAAC4mhwabnx8fOTi4qL09HS79vT0dPn5+RW77csvv6zJkyfro48+UsuWLYvsFxcXp8zMTNty9OjRcqkdAABUTA4NN66urgoNDbW7GPjixcHh4eFFbvfSSy9pwoQJWr9+vVq3bl3sPtzc3OTl5WW3AAAA63LoNTeSFBsbq4EDB6p169Zq06aNEhMTlZ2drejoaElSVFSU/P39lZCQIEl68cUXFR8fryVLligwMFBpaWmSJE9PT3l6ejrsOAAAQMXg8HDTt29fnThxQvHx8UpLS1NISIjWr19vu8g4NTVVzs7/m2B64403lJubqz59+tiNM3bsWD3//PNXs3QAAFABOTzcSFJMTIxiYmIKXbd582a714cPH77yBQEAgGvWNX23FAAAwF8RbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKU4PNzMnDlTgYGBcnd3V1hYmFJSUors+9133+mee+5RYGCgnJyclJiYePUKBQAA1wSHhpvly5crNjZWY8eO1fbt2xUcHKzIyEgdP3680P7nzp1TgwYNNHnyZPn5+V3lagEAwLXAoeFm6tSpGjZsmKKjoxUUFKRZs2bJw8ND8+bNK7T/zTffrClTpuj++++Xm5vbVa4WAABcCxwWbnJzc7Vt2zZFRET8rxhnZ0VERCg5Obnc9pOTk6OsrCy7BQAAWJfDwk1GRoby8vLk6+tr1+7r66u0tLRy209CQoK8vb1tS0BAQLmNDQAAKh6HX1B8pcXFxSkzM9O2HD161NElAQCAK6iSo3bs4+MjFxcXpaen27Wnp6eX68XCbm5uXJ8DAMDfiMNmblxdXRUaGqqkpCRbW35+vpKSkhQeHu6osgAAwDXOYTM3khQbG6uBAweqdevWatOmjRITE5Wdna3o6GhJUlRUlPz9/ZWQkCDpj4uQv//+e9t///zzz9qxY4c8PT3VqFEjhx0HAACoOBwabvr27asTJ04oPj5eaWlpCgkJ0fr1620XGaempsrZ+X+TS7/88otatWple/3yyy/r5ZdfVocOHbR58+arXT4AAKiAHBpuJCkmJkYxMTGFrvtrYAkMDJQx5ipUBQAArlWWv1sKAAD8vRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApVSIcDNz5kwFBgbK3d1dYWFhSklJKbb/ihUr1LRpU7m7u6tFixZat27dVaoUAABUdA4PN8uXL1dsbKzGjh2r7du3Kzg4WJGRkTp+/Hih/bds2aJ+/fppyJAh+uabb9SrVy/16tVLu3fvvsqVAwCAisjh4Wbq1KkaNmyYoqOjFRQUpFmzZsnDw0Pz5s0rtP+0adPUpUsXPfPMM2rWrJkmTJigm266Sa+99tpVrhwAAFREDg03ubm52rZtmyIiImxtzs7OioiIUHJycqHbJCcn2/WXpMjIyCL7AwCAv5dKjtx5RkaG8vLy5Ovra9fu6+urH374odBt0tLSCu2flpZWaP+cnBzl5OTYXmdmZkqSsrKyLqf0IuXnnLsi4wJWcKU+d1cbn3OgeFfis35xTGPMJfs6NNxcDQkJCRo3blyB9oCAAAdUA/y9eSc6ugIAV8OV/KyfOXNG3t7exfZxaLjx8fGRi4uL0tPT7drT09Pl5+dX6DZ+fn6l6h8XF6fY2Fjb6/z8fJ06dUo1a9aUk5PTZR4BKrKsrCwFBATo6NGj8vLycnQ5AK4QPut/D8YYnTlzRnXr1r1kX4eGG1dXV4WGhiopKUm9evWS9Ef4SEpKUkxMTKHbhIeHKykpSU888YStbePGjQoPDy+0v5ubm9zc3OzaqlWrVh7l4xrh5eXF//CAvwE+69Z3qRmbixx+Wio2NlYDBw5U69at1aZNGyUmJio7O1vR0dGSpKioKPn7+yshIUGSNGLECHXo0EGvvPKKunfvrmXLlunrr7/WW2+95cjDAAAAFYTDw03fvn114sQJxcfHKy0tTSEhIVq/fr3touHU1FQ5O//vpq62bdtqyZIlGjNmjJ599lk1btxYa9asUfPmzR11CAAAoAJxMiW57Bi4BuXk5CghIUFxcXEFTk0CsA4+6/grwg0AALAUhz+hGAAAoDwRbgAAgKUQbgAAgKUQbgAAV1zHjh3tnk8GXEmEG1wzBg0aZHvY40UrV66Uu7u7XnnlFQ0aNEhOTk6aPHmyXZ81a9bYPY168+bNcnJy0o033qi8vDy7vtWqVdOCBQuu1CEA15SSfqZKYvXq1ZowYUJ5llfAxXovLjVr1lSXLl307bffXtH9ouIh3OCaNWfOHPXv319vvPGGnnrqKUmSu7u7XnzxRZ0+ffqS2x88eFBvv/32lS4TuKaV5jNVnBo1aqhq1arlVFXRunTpomPHjunYsWNKSkpSpUqV1KNHjyu+X1QshBtck1566SU99thjWrZsme1p1pIUEREhPz8/2xOti/PYY49p7Nixdt8aD8BeST5TJ0+eVL9+/eTv7y8PDw+1aNFCS5cutevz59NSzz77rMLCwgqMExwcrPHjx9tez5kzR82aNZO7u7uaNm2q119//ZL1urm5yc/PT35+fgoJCdGoUaN09OhRnThxwtZn5MiRuuGGG+Th4aEGDRroueee0++//y5JOnz4sJydnfX111/bjZuYmKj69esrPz9fkrR792517dpVnp6e8vX11YABA5SRkWHrv3LlSrVo0UKVK1dWzZo1FRERoezs7EvWj/JBuME1Z+TIkZowYYI++OAD9e7d226di4uLJk2apBkzZuinn34qdpwnnnhCFy5c0IwZM65kucA1rSSfqfPnzys0NFRr167V7t279a9//UsDBgxQSkpKof379++vlJQUHThwwNb23Xff6dtvv9UDDzwgSVq8eLHi4+M1ceJE7dmzR5MmTdJzzz2nhQsXlrj2s2fPatGiRWrUqJFq1qxpa69ataoWLFig77//XtOmTdPs2bP16quvSpICAwMVERGh+fPn2401f/58DRo0SM7Ozvr111912223qVWrVvr666+1fv16paen67777pMkHTt2TP369dPgwYO1Z88ebd68WXfffbd4rNxVZIBrxMCBA42rq6uRZJKSkgpdf9dddxljjPnnP/9pBg8ebIwx5r333jN//lXftGmTkWROnz5tZs2aZWrUqGF+/fVXY4wx3t7eZv78+Vf8WIBrQUk/U4Xp3r27eeqpp2yvO3ToYEaMGGF7HRwcbMaPH297HRcXZ8LCwmyvGzZsaJYsWWI35oQJE0x4eHix9bq4uJgqVaqYKlWqGEmmTp06Ztu2bcXWOmXKFBMaGmp7vXz5clO9enVz/vx5Y4wx27ZtM05OTubQoUO2Ojp37mw3xtGjR40ks3fvXrNt2zYjyRw+fLjY/eLKYeYG15SWLVsqMDBQY8eO1dmzZ4vs9+KLL2rhwoXas2dPseMNGTJENWvW1IsvvljepQKWUtxnKi8vTxMmTFCLFi1Uo0YNeXp6asOGDUpNTS1yvP79+2vJkiWSJGOMli5dqv79+0uSsrOzdeDAAQ0ZMkSenp625YUXXrCb7SlMp06dtGPHDu3YsUMpKSmKjIxU165ddeTIEVuf5cuXq127dvLz85Onp6fGjBljV2uvXr3k4uKi9957T5K0YMECderUSYGBgZKknTt3atOmTXa1NW3aVJJ04MABBQcH6/bbb1eLFi107733avbs2Zd9zRJKh3CDa4q/v782b96sn3/+WV26dNGZM2cK7XfrrbcqMjJScXFxxY5XqVIlTZw4UdOmTdMvv/xyJUoGLKG4z9SUKVM0bdo0jRw5Ups2bdKOHTsUGRmp3NzcIsfr16+f9u7dq+3bt2vLli06evSo+vbtK0m2f7jMnj3bFlR27Nih3bt368svvyy2zipVqqhRo0Zq1KiRbr75Zs2ZM0fZ2dmaPXu2JCk5OVn9+/dXt27d9MEHH+ibb77R6NGj7Wp1dXVVVFSU5s+fr9zcXC1ZskSDBw+2rT979qx69uxpV9uOHTv0448/6tZbb5WLi4s2btyoDz/8UEFBQZoxY4aaNGmiQ4cOlfwNx2Vx+LeCA6VVv359ffrpp+rUqZO6dOmi9evXF3oXxuTJkxUSEqImTZoUO969996rKVOmaNy4cVeqZMASivpMffHFF7rrrrv04IMPSpLy8/O1b98+BQUFFTlWvXr11KFDBy1evFi//fab7rjjDtWuXVuS5Ovrq7p16+rgwYO22ZyycnJykrOzs3777TdJ0pYtW1S/fn2NHj3a1ufPszoXDR06VM2bN9frr7+uCxcu6O6777atu+mmm7Rq1SoFBgaqUqXC/4w6OTmpXbt2ateuneLj41W/fn299957io2NvazjQckwc4NrUkBAgDZv3qzjx48rMjJSWVlZBfq0aNFC/fv31/Tp0y853uTJkzVv3jzuZgCKUdRnqnHjxtq4caO2bNmiPXv26KGHHlJ6evolx+vfv7+WLVumFStWFAgx48aNU0JCgqZPn659+/Zp165dmj9/vqZOnVrsmDk5OUpLS1NaWpr27Nmjxx57zDbTcrHW1NRULVu2TAcOHND06dNtp5/+rFmzZvrnP/+pkSNHql+/fqpcubJt3aOPPqpTp06pX79+2rp1qw4cOKANGzYoOjpaeXl5+uqrrzRp0iR9/fXXSk1N1erVq3XixAk1a9bsku8JygfhBtesevXqafPmzcrIyCgy4IwfP95262ZxbrvtNt122226cOHClSgVsIzCPlNjxozRTTfdpMjISHXs2FF+fn4FHrhZmD59+ujkyZM6d+5cgf5Dhw7VnDlzNH/+fLVo0UIdOnTQggULdP311xc75vr161WnTh3VqVNHYWFh2rp1q1asWKGOHTtKku688049+eSTiomJUUhIiLZs2aLnnnuu0LGGDBmi3Nxcu1NSklS3bl198cUXysvLU+fOndWiRQs98cQTqlatmpydneXl5aX/+7//U7du3XTDDTdozJgxeuWVV9S1a9dLvicoH07GcG8aAAB/NWHCBK1YsYInHF+DmLkBAOBPzp49q927d+u1117TY4895uhyUAaEGwAA/iQmJkahoaHq2LFjgVNSuDZwWgoAAFgKMzcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcAAMBSCDcArqjk5GS5uLioe/fuji4FwN8Et4IDuKKGDh0qT09PzZ07V3v37lXdunUdUkdubq5cXV0dsm8AVxczNwCumLNnz2r58uUaPny4unfvrgULFtit/+9//6ubb75Z7u7u8vHxUe/evW3rcnJyNHLkSAUEBMjNzU2NGjXS3LlzJUkLFixQtWrV7MZas2aNnJycbK+ff/55hYSEaM6cObr++uvl7u4u6Y/vHmrfvr2qVaummjVrqkePHjpw4IDdWD/99JP69eunGjVqqEqVKmrdurW++uorHT58WM7Ozvr666/t+icmJqp+/fol+h4zAFce4QbAFfPuu++qadOmatKkiR588EHNmzdPFyeL165dq969e6tbt2765ptvlJSUpDZt2ti2jYqK0tKlSzV9+nTt2bNHb775pjw9PUu1//3792vVqlVavXq1duzYIUnKzs5WbGysvv76ayUlJcnZ2Vm9e/e2BZOzZ8+qQ4cO+vnnn/X+++9r586d+ve//638/HwFBgYqIiJC8+fPt9vP/PnzNWjQIDk7879UoEIwAHCFtG3b1iQmJhpjjPn999+Nj4+P2bRpkzHGmPDwcNO/f/9Ct9u7d6+RZDZu3Fjo+vnz5xtvb2+7tvfee8/8+X9pY8eONdddd505fvx4sTWeOHHCSDK7du0yxhjz5ptvmqpVq5qTJ08W2n/58uWmevXq5vz588YYY7Zt22acnJzMoUOHit0PgKuHf2YAuCL27t2rlJQU9evXT5JUqVIl9e3b13ZqaceOHbr99tsL3XbHjh1ycXFRhw4dLquG+vXrq1atWnZtP/74o/r166cGDRrIy8tLgYGBkqTU1FTbvlu1aqUaNWoUOmavXr3k4uKi9957T9Ifp8g6depkGweA41VydAEArGnu3Lm6cOGC3QXExhi5ubnptddeU+XKlYvctrh1kuTs7Gw7vXXR77//XqBflSpVCrT17NlT9evX1+zZs1W3bl3l5+erefPmys3NLdG+XV1dFRUVpfnz5+vuu+/WkiVLNG3atGK3AXB1MXMDoNxduHBBb7/9tl555RXt2LHDtuzcuVN169bV0qVL1bJlSyUlJRW6fYsWLZSfn69PP/200PW1atXSmTNnlJ2dbWu7eE1NcU6ePKm9e/dqzJgxuv3229WsWTOdPn3ark/Lli21Y8cOnTp1qshxhg4dqo8//livv/66Lly4oLvvvvuS+wZw9TBzA6DcffDBBzp9+rSGDBkib29vu3X33HOP5s6dqylTpuj2229Xw4YNdf/99+vChQtat26dRo4cqcDAQA0cOFCDBw/W9OnTFRwcrCNHjuj48eO67777FBYWJg8PDz377LN6/PHH9dVXXxW4E6sw1atXV82aNfXWW2+pTp06Sk1N1ahRo+z69OvXT5MmTVKvXr2UkJCgOnXq6JtvvlHdunUVHh4uSWrWrJn++c9/auTIkRo8ePAlZ3sAXF3M3AAod3PnzlVERESBYCP9EW6+/vpr1ahRQytWrND777+vkJAQ3XbbbUpJSbH1e+ONN9SnTx898sgjatq0qYYNG2abqalRo4YWLVqkdevWqUWLFlq6dKmef/75S9bl7OysZcuWadu2bWrevLmefPJJTZkyxa6Pq6urPvroI9WuXVvdunVTixYtNHnyZLm4uNj1GzJkiHJzczV48OAyvEMAriQe4gcAZTBhwgStWLFC3377raNLAfAXzNwAQCmcPXtWu3fv1muvvabHHnvM0eUAKAThBgBKISYmRqGhoerYsSOnpIAKitNSAADAUpi5AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlkK4AQAAlvL/WVpZ8tErlAwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['KNN', 'Naive Bayes'], [knn_accuracy, nb_accuracy])\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Classifier')\n",
    "plt.title('Classifier Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db7298",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "You are tasked with evaluating a simple binary classification model using a confusion matrix. The dataset involves predicting whether a given email is spam or not. To better understand the model's performance, you plan to extract specific metrics from the confusion matrix, specifically True Positives (TP) and False Positives (FP). Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a61dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 113\n",
      "False Positives: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# [Your code here] - Extract and print True Positives and False Positives\n",
    "tp = cm[1, 1]\n",
    "fp = cm[0, 1]\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3d05",
   "metadata": {},
   "source": [
    "Which snippet of code correctly extracts and prints the True Positives (TP) and False Positives (FP) from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54632b17",
   "metadata": {},
   "source": [
    "Which snippet of code correctly completes the setup to create a pipeline including `PolynomialFeatures` and `LogisticRegression`, fits it on the training data, and makes predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3781c44",
   "metadata": {},
   "source": [
    "## Question 15 (Medium)\n",
    "\n",
    "You are refining a logistic regression model to predict customer churn. The dataset includes various customer interaction metrics. To enhance your model, explore how polynomial features can improve prediction accuracy. This approach allows the model to capture complex interactions between variables. \n",
    "\n",
    "Here is your setup: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08305212",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of informative, redundant and repeated features must sum to less than the number of total features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate synthetic data for binary classification\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mmake_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_samples_generator.py:214\u001b[0m, in \u001b[0;36mmake_classification\u001b[1;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Count features, clusters and samples\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_informative \u001b[38;5;241m+\u001b[39m n_redundant \u001b[38;5;241m+\u001b[39m n_repeated \u001b[38;5;241m>\u001b[39m n_features:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of informative, redundant and repeated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures must sum to less than the number of total\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Use log2 to avoid overflow errors\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_informative \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(n_classes \u001b[38;5;241m*\u001b[39m n_clusters_per_class):\n",
      "\u001b[1;31mValueError\u001b[0m: Number of informative, redundant and repeated features must sum to less than the number of total features"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=3, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply polynomial features manually\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a2e94",
   "metadata": {},
   "source": [
    "What is the correct procedure to fit a logistic regression model on the training data after transforming it with polynomial features, and how should predictions be made on the test data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
