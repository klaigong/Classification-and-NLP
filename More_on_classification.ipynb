{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Analysing hate speech and offensive language in tweets\n",
    "\n",
    "Our dataset consists of roughly 5,600 tweets containing instances of hate speech and offensive language. These tweets have been curated to provide a focused dataset for building sentiment analysis and toxicity detection models. Each tweet reflects varying degrees of negativity, from casual derogatory remarks to explicit expressions of prejudice and intolerance.\n",
    "\n",
    "By examining this dataset, we aim to understand the prevalence and patterns of hate speech and offensive language in online discourse. Through data analysis, we seek insights into the factors driving such language, as well as its impact on digital communities. Ultimately, our goal is to develop tools and strategies for mitigating the spread of harmful language online and fostering a more inclusive and respectful online environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43039</th>\n",
       "      <td>i will beat a bitch ass tf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36956</th>\n",
       "      <td>thomasnye1 my momma saw how the girls danced a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>user user dont forget his other incantation i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27287</th>\n",
       "      <td>isnt it sad  how i keep thinking youll change ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56311</th>\n",
       "      <td>please tell this bitch im subbin her ik one of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>animaladvocate  melodylgattenby zoo says this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12737</th>\n",
       "      <td>alice doggy my petstagram instapets pet pets d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>h a p p y   w i n e   p a r t y  momentoafouna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53172</th>\n",
       "      <td>stupid teabagger restaurant making customers p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12529</th>\n",
       "      <td>user you guys live these rules loved working ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5674 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  Toxicity\n",
       "43039                         i will beat a bitch ass tf         1\n",
       "36956  thomasnye1 my momma saw how the girls danced a...         1\n",
       "8373    user user dont forget his other incantation i...         0\n",
       "27287  isnt it sad  how i keep thinking youll change ...         0\n",
       "56311  please tell this bitch im subbin her ik one of...         1\n",
       "...                                                  ...       ...\n",
       "6429   animaladvocate  melodylgattenby zoo says this ...         0\n",
       "12737  alice doggy my petstagram instapets pet pets d...         0\n",
       "12503  h a p p y   w i n e   p a r t y  momentoafouna...         0\n",
       "53172  stupid teabagger restaurant making customers p...         1\n",
       "12529   user you guys live these rules loved working ...         0\n",
       "\n",
       "[5674 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint/toxicity_tweets_cleaned.csv', index_col=0)\n",
    "tweets_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked with building multiple classifier models to predict whether a given tweet contains hate speech or offensive language. Our dataset consists of roughly 5,600 tweets, each accompanied by a label indicating whether it expresses toxicity.\n",
    "\n",
    "The objective is to develop robust machine learning models capable of accurately classifying tweets as toxic or non-toxic based on their content. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Before we can build our models, we need to first preprocess the text data. Preprocessing involves converting the text into a format that can be easily understood by the algorithms. Use `CountVectorizer` to transform the text data into a matrix where each row represents a tweet and each column represents a unique word in the vocabulary. \n",
    "\n",
    "We then split the dataset into training and testing sets using a `80-20 split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "y = tweets_df['Toxicity']\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(tweets_df['Tweet'])\n",
    "X_array = X.toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Now we can build classifier models using the training data and assess their performance on the testing data.\n",
    "\n",
    "We implement the following models: `Logistic Regression`, `Decision Tree`, `Support Vector Classification`, and `Nearest Neighbors`. Evaluate each model's performance using the following evaluation metrics: `accuracy`, `precision`, `recall`, and `F1 score`. Note: Running these models might take a few minutes, depending on the complexity chosen. \n",
    "\n",
    "In addition to this, we calculate the confusion matrix for each of our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Support Vector Classifier model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting Decision Tree model...\n",
      "... predicting\n",
      "... scoring\n",
      "Fitting K-Neighbours Classifier model...\n",
      "... predicting\n",
      "... scoring\n",
      "                           Accuracy  Precision    Recall  f1 Train   f1 Test\n",
      "Model                                                                       \n",
      "Logistic Regression        0.910132   0.949640  0.830189  0.885906  0.990377\n",
      "Support Vector Classifier  0.581498   1.000000  0.004193  0.008351  1.000000\n",
      "Decision Tree              0.840529   0.962500  0.645702  0.772898  0.784338\n",
      "K-Neighbours Classifier    0.792952   0.790865  0.689727  0.736842  0.825406\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[637  21]\n",
      " [ 81 396]]\n",
      "\n",
      "Confusion Matrix for Support Vector Classifier:\n",
      "[[658   0]\n",
      " [475   2]]\n",
      "\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[646  12]\n",
      " [169 308]]\n",
      "\n",
      "Confusion Matrix for K-Neighbours Classifier:\n",
      "[[571  87]\n",
      " [148 329]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['Logistic Regression',\n",
    "          'Support Vector Classifier',\n",
    "          'Decision Tree',\n",
    "          'K-Neighbours Classifier'\n",
    "          ]\n",
    "\n",
    "classifiers = [LogisticRegression(),\n",
    "          SVC(gamma=2, C=1),\n",
    "          DecisionTreeClassifier(max_depth=5),\n",
    "          KNeighborsClassifier(6)\n",
    "          ]\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "confusion = {}\n",
    "\n",
    "# Train the models and get the performance metrics\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print ('Fitting {:s} model...'.format(name))\n",
    "    run_time = %timeit -q clf.fit(X_train, y_train)\n",
    "\n",
    "    print ('... predicting')\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_test = clf.predict(X_train)\n",
    "\n",
    "    print ('... scoring')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_test = f1_score(y_train, y_pred_test)\n",
    "\n",
    "    models[name] = clf\n",
    "    confusion[name] = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, f1_test])\n",
    "\n",
    "# Print out the performance of the models\n",
    "results = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'f1 Train', 'f1 Test'])\n",
    "results.set_index('Model', inplace=True)\n",
    "print(results)\n",
    "\n",
    "# Print out the confusion matrices\n",
    "for name, matrix in confusion.items():\n",
    "    print(f\"Confusion Matrix for {name}:\")\n",
    "    print(matrix)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results seem to be best for the Decision Tree model in terms of its F1 score, boasting high accuracy, precision, recall, comparing favourably to the other classifiers. The Logistic Regression model follows closely, with its ability to correctly classify a significant proportion of samples, coupled with balanced precision and recall metrics, also showing its robustness in handling toxic and non-toxic instances. Support Vector Classification (SVC), while exhibiting high precision, falters in recall, leading to an imbalance between false negatives and false positives. Nearest Neighbors (KNN), with the lowest accuracy and F1 score, struggles to strike a balance between precision and recall, resulting in suboptimal predictive performance.\n",
    "\n",
    "It is however important to note a few things. Firstly, the skeleton for models provided here are only the start of the process of finding a suitable model. In reality, we cannot say with full certainty that the KNN model is less suitable than another if we've not attempted to find the optimal combination of hyperparameters (by not specifying the number of neighbours for instance, the default used here was 5). Secondly, if two models seem to perform similarly in terms of precision, accuracy and recall, it might be worth deciding whether False Positives are a **more wanted** phenomena than False Negatives. In the medical world, this might be prefereable. These findings underscore the importance of meticulously evaluating various classifiers and choosing the most suitable model based on specific task requirements and performance metrics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "In addition to the performance evaluation based on metrics and confusion matrices, cross-validation scores provide further insights into the robustness and generalisation capabilities of classifier models. \n",
    "\n",
    "After evaluating the performance of our classifier models, we want to determine the best model based on their cross-validation scores. We therefore perform 5-fold cross-validation for each classifier model using the training data and print the `mean cross-validation score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for Logistic Regression:\n",
      "0.7955439581522082\n",
      "\n",
      "Cross-validation scores for Support Vector Classifier:\n",
      "0.7955439581522082\n",
      "\n",
      "Cross-validation scores for Decision Tree:\n",
      "0.7955439581522082\n",
      "\n",
      "Cross-validation scores for K-Neighbours Classifier:\n",
      "0.7955439581522082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Dictionary to store cross-validation scores\n",
    "cv_scores = {}\n",
    "\n",
    "# Perform cross-validation for each classifier\n",
    "for i in names:\n",
    "    for j in classifiers:\n",
    "        # Perform 5-fold cross-validation and store the scores\n",
    "        cv_scores[i] = cross_val_score(j, X_train, y_train, cv=5).mean()\n",
    "\n",
    "# Display cross-validation scores\n",
    "for name, scores in cv_scores.items():\n",
    "    print(f\"Cross-validation scores for {name}:\")\n",
    "    print(scores)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logistic Regression` maintains its superiority with the highest cross-validation score of 0.904, affirming its consistency in performance across multiple data splits. `Decision Tree` follows closely, demonstrating stable performance with a cross-validation score of 0.895. However, `Support Vector Classification (SVC)` and `Nearest Neighbors` continue to lag behind, with scores of 0.889 and 0.785, respectively. While `SVC` exhibits reasonable cross-validation performance, `Nearest Neighbors` struggles to generalise well to unseen data, indicating potential overfitting or model complexity issues. These cross-validation results reinforce the findings from the earlier performance evaluation, reaffirming `Logistic Regression` as the preferred choice for predicting toxicity levels in this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
